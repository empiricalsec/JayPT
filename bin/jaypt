#!/usr/bin/env ruby

require_relative "../lib/jaypt"
require "csv"
require "concurrent-ruby"

$stderr = File.open("errors.log", "w")

models = [
  "google/gemini-2.5-pro-preview",
  # "x-ai/grok-3-beta",
  "anthropic/claude-3.7-sonnet",
  "openai/gpt-4o-mini"
]

POOL_SIZE = 100
CHUNK_SIZE = 50

if ARGV[1]
  raise "Second argument must be an output CSV file" if ARGV[1] !~ /\.csv$/

  puts "Models: #{models.join(', ')}"
  puts "Writing to #{ARGV[1]}"
  puts "Pool size: #{POOL_SIZE}"

  pool = Concurrent::FixedThreadPool.new(POOL_SIZE)
  identifiers = File.readlines(ARGV.first, chomp: true)
  total_chunks = (identifiers.size.to_f / CHUNK_SIZE).ceil

  identifiers.each_slice(CHUNK_SIZE).with_index do |chunk, chunk_idx|
    futures = []

    chunk.each do |identifier|
      models.each do |model|
        futures << Concurrent::Promises.future_on(pool) do
          agent = JayPT::Agent.new(model:)
          res = agent.score_cve(identifier)
          [model, identifier, res[:score], res[:analysis], res[:inference_time].round(1), res[:input_tokens], res[:output_tokens]]
        rescue StandardError => e
          [model, identifier, 0, "ERROR: #{e.class} - #{e.message[0..100]}", 0, 0, 0]
        end
      end
    end

    # Wait for all futures in this chunk
    results = Concurrent::Promises.zip(*futures).value!

    # Write results to CSV (append mode, header only for first chunk)
    CSV.open(ARGV[1], chunk_idx == 0 ? "w" : "a") do |csv|
      csv << %w[model cve score analysis inference_time input_tokens output_tokens] if chunk_idx == 0
      results.each { |row| csv << row }
    end

    puts "Processed chunk #{chunk_idx + 1}/#{total_chunks} (#{chunk.size} identifiers)"
  end
else
  puts "Running models against #{ARGV.first}\n\n"

  threads = models.map do |model|
    Thread.new do
      agent = JayPT::Agent.new(model:)
      results = agent.score_cve(ARGV.first)

      puts <<~OUTPUT
        Model: #{model}
        Score: #{results[:score]}
        Analysis: #{results[:analysis]}
        Inference time: #{results[:inference_time].round(1)} seconds
        Input tokens: #{results[:input_tokens]}
        Output tokens: #{results[:output_tokens]}

      OUTPUT
    rescue StandardError => e
      puts <<~OUTPUT
        Model: #{model}
        Error: #{e.class} - #{e.message}

      OUTPUT
    end
  end

  threads.each(&:join)
end
